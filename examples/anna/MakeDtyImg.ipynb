{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses code snippets from the crocodile python examples (https://github.com/SKA-ScienceDataProcessor/crocodile) to perform w-projection convolutional gridding of a set of continuous visibilities, followed by a Fourier Transform the grid to form a Dirty Image.\n",
    "\n",
    "To run the script you will need:\n",
    " - ipython\n",
    " - numpy\n",
    " - pylab\n",
    " - simulated_data.txt (or any other set of visibility data stored as a text file with columns (u, v, w, real(V), imag(V)).\n",
    " \n",
    "The first three of these can be easily obtained using pip. \n",
    "\n",
    "To get pip: \n",
    "\n",
    "> apt-get install python-pip\n",
    "\n",
    "To install each library:\n",
    "\n",
    ">pip install numpy\n",
    "\n",
    "etc.\n",
    "\n",
    "The fourth is a text file created by Simulate_uvw.ipynb. This script assumes it is in the working directory. \n",
    "\n",
    "\n",
    "Set up python stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as pl\n",
    "pl.rcParams['figure.figsize'] = 16, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we're going to define some user-supplied parameters:\n",
    "\n",
    "1. The w-increment\n",
    "2. The kernel over-sampling factor\n",
    "3. The kernel support size\n",
    "4. The kernel far-field size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wstep=300\n",
    "over_sampling=8\n",
    "ff_size=256\n",
    "kernel_support=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we're going to get some visibility data. You can create these data using the Simulate_uvw.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u,v,w,vis_re,vis_im = numpy.loadtxt('./simulated_data.txt',unpack=True)\n",
    "vis = vis_re + 1j*vis_im\n",
    "uvw = numpy.column_stack((u,v,w))\n",
    "\n",
    "# conjugate symmetry\n",
    "tmp_uvw = uvw*numpy.array([-1.,-1.,1.])\n",
    "tmp_vis = vis_re - 1j*vis_im\n",
    "\n",
    "vis = numpy.hstack((vis,tmp_vis))\n",
    "uvw = numpy.vstack((uvw,tmp_uvw))\n",
    "\n",
    "pl.subplot(111)\n",
    "pl.scatter(uvw[:,0],uvw[:,1])\n",
    "pl.show()\n",
    "print \"Range of w-values:\",numpy.amin(uvw[:,2]),\" - \",numpy.amax(uvw[:,2]),\" lambda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image parameters are defined in terms of the half-width of the FOV, T2, and the half-width of the uv-plane, L2, which is used as an approximation to the angular resolution. \n",
    "\n",
    "The number of pixels on the side of an image is \n",
    "\n",
    "$$N_{\\rm pix} = \\frac{\\Theta_{\\rm FOV}} {\\theta_{\\rm res}}.$$\n",
    "\n",
    "Therefore the number of pixels along a side is given by \n",
    "\n",
    "$$N_{\\rm pix} = 2 T_{1/2}\\times 2 L_{1/2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T2 = 0.002 # half-width of FOV [radians]\n",
    "L2 = 30000 # half-width of uv-plane [lambda]\n",
    "N = int(T2*L2*4) # number of pixels \n",
    "print \"Making grids of side: \",N,\" pixels.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty grid to grid visibilities onto, as well as a grid for weights to make the synthesized beam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_uv=numpy.zeros([N, N], dtype=complex)\n",
    "grid_wt=numpy.zeros([N, N], dtype=complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the uvw and visibility data by w:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp=uvw\n",
    "zs=numpy.argsort(uvw[:,2])\n",
    "uvw = uvw[zs]\n",
    "vis = vis[zs]\n",
    "\n",
    "pl.subplot(121)\n",
    "pl.plot(temp[:,2])\n",
    "pl.title(\"Before\")\n",
    "pl.subplot(122)\n",
    "pl.plot(uvw[:,2])\n",
    "pl.title(\"After\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create an array of w-planes spanning the range of w -values in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ii=range(0, len(vis), wstep)\n",
    "print ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of boundaries in w-value for each plane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ir=zip(ii[:-1], ii[1:]) + [(ii[-1], len(vis))]\n",
    "print ir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each set of limits constitutes a w-plane. With the limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ilow,ihigh=ir[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each plane we need to calculate the mean w-value in the uvw-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w=uvw[ilow:ihigh,2].mean()\n",
    "print w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some drawing tools that will be useful in a second..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_image(ff, name, w_dep=False):\n",
    "    # Determine mid position and size of image\n",
    "    size = ff.shape[0]/2\n",
    "    lm_size = 2*size*T2/N\n",
    "    pl.subplot(121)\n",
    "    pl.imshow(ff.real, extent=(-lm_size,lm_size,-lm_size,lm_size))\n",
    "    pl.title(\"$%s(l,m%s)$: Real\" % (name, \",w\" if w_dep else \"\"))\n",
    "    pl.xlabel(r\"L [$1$]\"); pl.ylabel(r\"M [$1$]\")\n",
    "    pl.subplot(122)\n",
    "    pl.imshow(ff.imag, extent=(-lm_size,lm_size,-lm_size,lm_size))\n",
    "    pl.title(\"$%s(l,m%s)$: Imag\" % (name, \",w\" if w_dep else \"\"))\n",
    "    pl.xlabel(r\"L [$1$]\"); pl.ylabel(r\"M [$1$]\")\n",
    "    pl.show()\n",
    "def show_grid(af, name, norm=None, size=None, over=None):\n",
    "    # Determine mid position and size of grid portion. Factor in oversampling.\n",
    "    mid = af.shape[0]/2\n",
    "    if size is None:\n",
    "        size = af.shape[0]/2\n",
    "    elif over is not None:\n",
    "        size *= over\n",
    "    uv_size = 2*size*L2/N    \n",
    "    if over is not None:\n",
    "        uv_size /= over\n",
    "    # Determine normalisation for image.\n",
    "    from  matplotlib.colors import Normalize\n",
    "    if norm is not None:\n",
    "        norm = Normalize(vmin=-norm, vmax=norm, clip=True)\n",
    "    else:\n",
    "        norm = None\n",
    "    # Draw.\n",
    "    for plot, comp, data in [(121, \"Real\", af.real), (122, \"Imag\", af.imag)]:\n",
    "        pl.subplot(plot)\n",
    "        pl.imshow(data[mid-size:mid+size+1,mid-size:mid+size+1],\n",
    "                  extent=(-uv_size, uv_size, -uv_size, uv_size),\n",
    "                  norm=norm)\n",
    "        pl.title(\"$%s(u,v,w)$: %s\" % (name, comp))\n",
    "        pl.xlabel(r\"U [$\\lambda$]\")\n",
    "        pl.ylabel(r\"V [$\\lambda$]\")\n",
    "        # Only show color bar if we don't use the standard normalisation.\n",
    "        if norm is None: pl.colorbar(shrink=.4,pad=0.025)\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to caluclate the w-kernel for this w-value. First we create a grid for the kernel with values\n",
    "\n",
    "$$r^2 = \\ell^2 + m^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upfront_oversampling = over_sampling\n",
    "ff = T2*numpy.mgrid[-upfront_oversampling:upfront_oversampling-2./ff_size:(ff_size*upfront_oversampling*1j),\n",
    "                    -upfront_oversampling:upfront_oversampling-2./ff_size:(ff_size*upfront_oversampling*1j)]\n",
    "r2 = (ff[0])**2 + (ff[1])**2\n",
    "show_image(r2, 'R', w_dep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then calculate the value of the kernel at each point, \n",
    "\n",
    "$$G(\\ell,m,w) = {\\rm e}^{-2\\pi i  \\left[w( \\sqrt{1-\\ell^2-m^2} - 1 )\\right] } $$\n",
    "\n",
    "(Eq. 11; Cornwell+ 2008 http://arxiv.org/pdf/0807.4161v1.pdf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ph=w*(numpy.sqrt(1.-r2)-1.)\n",
    "cp=numpy.exp(-2j*numpy.pi*ph)\n",
    "show_image(cp, 'G', w_dep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pad this and FFT it in order to over-sample it in uvw-space to obtain the kernel:\n",
    "\n",
    "$$ \\tilde{G}(u,v,w) \\approx \\frac{i}{w}{\\rm e}^{ \\pi i \\left[ \\frac{u^2 +v^2}{w} \\right] } $$\n",
    "\n",
    "(Eq. 14; Cornwell+ 2008 http://arxiv.org/pdf/0807.4161v1.pdf , however using FFT we obtain a more accurate version here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "padff=numpy.pad(cp, \n",
    "    pad_width=int(ff_size*(over_sampling/upfront_oversampling-1.)/2.),\n",
    "    mode='constant',\n",
    "    constant_values=(0.0,))\n",
    "show_image(padff, \"G\", w_dep=True)\n",
    "\n",
    "af=numpy.fft.fftshift(numpy.fft.ifft2(numpy.fft.ifftshift(padff)))\n",
    "show_grid(af, r\"\\tilde G\", norm=.5, over=over_sampling, size=kernel_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can quickly check whether the kernel support is large enough to contain most of the kernel. If this fails, try increasing `kernel_support`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "af_sum = af.sum()\n",
    "print \"Full sum:\", af_sum\n",
    "assert(abs(af_sum - 1.0) < 1e-13)\n",
    "\n",
    "mid=over_sampling*ff_size/2; size = over_sampling*kernel_support\n",
    "af_part_sum = af[mid-size:mid+size+1,mid-size:mid+size+1].sum()\n",
    "print \"Kernel sum:\", af_part_sum, abs(af_part_sum - 1.0)\n",
    "assert(abs(af_part_sum - 1.0) < 5e-4) # quality check - increase kernel_support if this fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift\n",
    "\n",
    "We intend to shift the FoV by a certain $(\\Delta l, \\Delta m)$ for faceting. This requires phase-rotating the visibilities:\n",
    "\n",
    "$$V^{shift}(u,v,w) = e^{2\\pi i (u\\Delta l + v\\Delta m)}V(u,v,w)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta_l = 0.0000 # 2 * T2\n",
    "delta_m = 0.0000\n",
    "\n",
    "shift = numpy.exp(2j*numpy.pi* (uvw[:,0]*delta_l+uvw[:,1]*delta_m))\n",
    "vis_shift = vis * shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As well as updating the grid convolution function. This would be a simple shift in the image plane, but for quality it is probably better to do this afterwards. As we are going to FFT the convolution $V * \\tilde G$, it is not particularly surprising that this yields the same transformation we did for the visibilities:\n",
    "\n",
    "$$\\tilde G^{shift}(u,v,w) = e^{2\\pi i (u\\Delta m + v\\Delta l)} \\tilde G(u,v,w)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff = L2/N * numpy.mgrid[-ff_size:ff_size-2./over_sampling:(ff_size*over_sampling*1j),\n",
    "                        -ff_size:ff_size-2./over_sampling:(ff_size*over_sampling*1j)]\n",
    "rot = numpy.exp(2j*numpy.pi*(ff[1] * delta_l + ff[0] * delta_m))\n",
    "af_shift = rot * af\n",
    "\n",
    "mid = ff_size*over_sampling/2\n",
    "size = over_sampling*kernel_support\n",
    "\n",
    "show_grid(rot, \"rot\", size=kernel_support, over=over_sampling)\n",
    "show_grid(af_shift, r\"\\tilde G^{shift}\", size=kernel_support, over=over_sampling, norm=.5)\n",
    "show_grid(af_shift - af, r\"\\left(\\tilde G^{shift} - \\tilde G\\right)\", size=kernel_support, over=over_sampling)\n",
    "\n",
    "show_image(numpy.fft.ifftshift(numpy.fft.fft2(numpy.fft.fftshift(af_shift))), r\"G^{shift}\", w_dep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "We might also want to distort our image in a linear fashion in order to compensate for projection errors far from the phase centre:\n",
    "\n",
    "\n",
    "$$I^{trans}(l,m) = I^{shift}(T_{2\\times2}(l,m))$$\n",
    "$$T_{2\\times2} = \\begin{pmatrix} t_{11} & t_{12} \\\\ t_{21} & t_{22} \\end{pmatrix} $$\n",
    "\n",
    "This comes down to a transformation of $uv$ coordinates:\n",
    "\n",
    "$$V^{trans}(u,v,w) = V^{shift}\\bigl(\\left(T^T_{2\\times2}(u,v)\\right)^{-1},w\\bigr)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transformation matrix\n",
    "import math\n",
    "a = 0 * numpy.pi / 2; s = 1.0\n",
    "t_11 = s * math.cos(a); t_12 = s * -math.sin(a)\n",
    "t_21 = s * math.sin(a); t_22 = s * math.cos(a)\n",
    "\n",
    "# Determinant, inverse transposed\n",
    "det = float(t_11 * t_22 - t_12 * t_21)\n",
    "tti_11 =  t_22 / det; tti_12 = -t_12 / det\n",
    "tti_21 = -t_21 / det; tti_22 =  t_11 / det\n",
    "\n",
    "# New UV coordinates\n",
    "u_trans = tti_11 * uvw[:,0] + tti_12 * uvw[:,1]\n",
    "v_trans = tti_21 * uvw[:,0] + tti_22 * uvw[:,1]\n",
    "uvw_trans = numpy.array([u_trans, v_trans, uvw[:,2]]).T\n",
    "\n",
    "# Also shift intensity\n",
    "vis_trans = vis_shift / abs(det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating the GCF is theoretically exactly as straightforward. All we need to do is:\n",
    "\n",
    "$$\\tilde G^{trans} = G^{shift}\\bigl(\\left(T^T_{2\\times2}(u,v)\\right)^{-1},w\\bigr)$$\n",
    "\n",
    "This is actually a non-trivial image transformation this time around. Here is a rough version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff = numpy.mgrid[-float(ff_size):ff_size-2./over_sampling:(ff_size*over_sampling*1j),\n",
    "                 -float(ff_size):ff_size-2./over_sampling:(ff_size*over_sampling*1j)]\n",
    "\n",
    "print tti_11, tti_12\n",
    "print tti_21, tti_22\n",
    "\n",
    "xs = (over_sampling/2.*(ff_size + tti_11 * ff[1] + tti_12 * ff[0]))\n",
    "ys = (over_sampling/2.*(ff_size + tti_21 * ff[1] + tti_22 * ff[0]))\n",
    "xs = numpy.minimum(numpy.maximum(xs, 0), ff_size * over_sampling - 1)\n",
    "ys = numpy.minimum(numpy.maximum(ys, 0), ff_size * over_sampling - 1)\n",
    "xrem = numpy.remainder(xs,1)\n",
    "yrem = numpy.remainder(ys,1)\n",
    "\n",
    "ixs = xs.astype(int); iys = ys.astype(int)\n",
    "def inc(i): return (i+1)%(ff_size*over_sampling)\n",
    "af_trans =  (\n",
    "  (1-yrem) * ((1-xrem) * af_shift[iys,        ixs] + xrem * af_shift[iys,        inc(ixs)]) +\n",
    "     yrem  * ((1-xrem) * af_shift[inc(iys+1), ixs] + xrem * af_shift[inc(iys+1), inc(ixs)]))\n",
    "\n",
    "show_grid(af_trans, r\"\\tilde G^{trans}\", size=kernel_support, over=over_sampling, norm=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily check that at this point we have moved and transformed the image plane. We just have to reverse the FFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_image(numpy.fft.ifftshift(numpy.fft.fft2(numpy.fft.fftshift(af_trans))), \"G^{trans}\", w_dep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is more accurate if we go a step back, generate the original $G$ for the transformed coordinates, then re-do the shift in the new coordinate system. So basically we do:\n",
    "\n",
    "$$G^{trans-shift}(l,m,w) = G(T_{2\\times2}(l,m),w)$$\n",
    "\n",
    "followed by:\n",
    "\n",
    "$$\\tilde G^{shift}(u,v,w) = e^{2\\pi i (u,v) \\cdot T_{2\\times2}(\\Delta l, \\Delta m)} \\tilde G^{trans-shift}(u,v,w)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ff = T2*numpy.mgrid[-upfront_oversampling:upfront_oversampling-2./ff_size:(ff_size*upfront_oversampling*1j),\n",
    "                    -upfront_oversampling:upfront_oversampling-2./ff_size:(ff_size*upfront_oversampling*1j)]\n",
    "t_ls = t_11 * ff[1] + t_12 * ff[0]\n",
    "t_ms = t_21 * ff[1] + t_22 * ff[0]\n",
    "r2 = t_ls**2 + t_ms**2\n",
    "ph=w*(1.-numpy.sqrt(1.-r2))\n",
    "cp=numpy.exp(2j*numpy.pi*ph)\n",
    "padff=numpy.pad(cp, \n",
    "    pad_width=int(ff_size*(over_sampling/upfront_oversampling-1.)/2.),\n",
    "    mode='constant',\n",
    "    constant_values=(0.0,))\n",
    "show_image(padff, \"G^{trans2}\", w_dep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "af_trans_shift=numpy.fft.fftshift(numpy.fft.ifft2(numpy.fft.ifftshift(padff)))\n",
    "show_grid(af_trans_shift, r\"\\tilde G^{trans-shift}\", size=kernel_support, over=over_sampling, norm=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff = (1/T2/4) * numpy.mgrid[-ff_size:ff_size-2./over_sampling:(ff_size*over_sampling*1j),\n",
    "                            -ff_size:ff_size-2./over_sampling:(ff_size*over_sampling*1j)]\n",
    "t_delta_l = t_11 * delta_l + t_12 * delta_m\n",
    "t_delta_m = t_21 * delta_l + t_22 * delta_m\n",
    "rot = numpy.exp(2j*numpy.pi*(ff[1] * t_delta_l + ff[0] * t_delta_m)/det)\n",
    "af_trans2 = rot * af_trans_shift\n",
    "show_grid(rot, \"rot\", size=kernel_support, over=over_sampling)\n",
    "show_grid(af_trans2, r\"\\tilde G^{trans2}\", size=kernel_support, over=over_sampling, norm=.5)\n",
    "show_grid(af_trans - af_trans2, r\"\\left(\\tilde G^{trans} - \\tilde G^{trans2}\\right)\", size=kernel_support, over=over_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff_back = numpy.fft.ifftshift(numpy.fft.fft2(numpy.fft.fftshift(af_trans)))\n",
    "ff_back2 = numpy.fft.ifftshift(numpy.fft.fft2(numpy.fft.fftshift(af_trans2)))\n",
    "pl.subplot(121)\n",
    "pl.imshow(ff_back.real)\n",
    "pl.title(r\"$G^{trans}(l,m,w)$: Real\")\n",
    "pl.subplot(122)\n",
    "pl.imshow(ff_back.imag)\n",
    "pl.title(r\"$G^{trans}(l,m,w)$: Imag\")\n",
    "pl.show()\n",
    "pl.subplot(121)\n",
    "pl.imshow(ff_back2.real)\n",
    "pl.title(r\"$G^{trans2}(l,m,w)$: Real\")\n",
    "pl.subplot(122)\n",
    "pl.imshow(ff_back2.imag)\n",
    "pl.title(r\"$G^{trans2}(l,m,w)$: Imag\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then just extract the central region with size equal to the kernel support. I've added a couple of options for this: (1) from crocodile; (2) adapted from ASKAPsoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def exmid2(a, s):\n",
    "    \"\"\"Extract a section from middle of a map, suitable for zero frequencies at N/2\"\"\"\n",
    "    cx=a.shape[0]/2\n",
    "    cy=a.shape[1]/2\n",
    "    return a[cy-s-1:cy+s,cx-s-1:cx+s]\n",
    "\n",
    "# works in the opposite sense to ASKAPsoft, which calculates an under-sampled kernel and \n",
    "# interpolates.\n",
    "def wextract(a, i, j, Qpx, s):\n",
    "    \"\"\"Extract the (ith,jth) w-kernel from the oversampled parent and normalise\n",
    "    The kernel is reversed in order to make the suitable for\n",
    "    correcting the fractional coordinates\n",
    "    \"\"\"\n",
    "    x=a[j::Qpx, i::Qpx] # decimate the kernel\n",
    "    x=x[::-1,::-1] # reverse the kernel\n",
    "\n",
    "    # extract middle, normalise (don't update x, that would write a!)\n",
    "    norm=float(Qpx*Qpx)\n",
    "    #norm=1.0/x.sum()\n",
    "    print x.sum()\n",
    "    return norm*exmid2(x,s)\n",
    "\n",
    "def askapsoft_decimate_n_extract(af, over_sampling, kernel_support):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracted and translated from\n",
    "    AWProjectVisGridder.cc\n",
    "    \"\"\"\n",
    "    \n",
    "    # why is this normalization required..?\n",
    "    rescale = over_sampling*over_sampling\n",
    "            \n",
    "    cSize = 2 * kernel_support + 1\n",
    "    itsConvFunc=numpy.zeros((over_sampling, over_sampling, cSize, cSize), dtype=complex)\n",
    "            \n",
    "    for fracu in range(0,over_sampling):\n",
    "        for fracv in range(0,over_sampling):\n",
    "            \n",
    "            # Now cut out the inner part of the convolution function and\n",
    "            # insert it into the convolution function\n",
    "            for iy in range(-kernel_support,kernel_support+1):\n",
    "                for ix in range(-kernel_support,kernel_support+1):\n",
    "                    \n",
    "                    nx = af.shape[0]\n",
    "                    ny = af.shape[1]\n",
    "                    \n",
    "                    # assumes support is the same for all w-planes:\n",
    "                    xval = (ix) * over_sampling + fracu + nx / 2\n",
    "                    yval = (iy) * over_sampling + fracv + ny / 2\n",
    "                    \n",
    "                    itsConvFunc[fracv, fracu, iy+cSize/2, ix+cSize/2] \\\n",
    "                            = rescale * af[xval, yval]\n",
    "                        \n",
    "    return itsConvFunc\n",
    "\n",
    "# --------------------------\n",
    "# --------------------------\n",
    "# Option (1):\n",
    "wg=[[wextract(af, i, j, over_sampling, kernel_support) for i in range(over_sampling)] for j in range(over_sampling)]\n",
    "# Convert list to numpy array:\n",
    "wg = numpy.array(wg)\n",
    "# --------------------------\n",
    "# Option (2):\n",
    "#wg = askapsoft_decimate_n_extract(af, over_sampling, kernel_support)\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "for fracu in range(0,over_sampling):\n",
    "    show_grid(wg[0,fracu,:,:], r\"\\tilde G\", size=kernel_support, norm=.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for $\\tilde G^{shift}$. This is the kernel we are actually interested in, but constructing both gives us a chance to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wg_shift =[[wextract(af_shift, i, j, over_sampling, kernel_support) for i in range(over_sampling)] for j in range(over_sampling)]\n",
    "wg_shift = numpy.array(wg_shift)\n",
    "wgd = wg_shift-wg\n",
    "\n",
    "show_grid(wgd[2,2,:,:], r\"\\tilde G^{shift}\", size=kernel_support, norm=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, this time for $\\tilde G^{trans}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wg_trans =[[wextract(af_trans, i, j, over_sampling, kernel_support) for i in range(over_sampling)] for j in range(over_sampling)]\n",
    "wg_trans = numpy.array(wg_trans)\n",
    "wg_trans2 =[[wextract(af_trans2, i, j, over_sampling, kernel_support) for i in range(over_sampling)] for j in range(over_sampling)]\n",
    "wg_trans2 = numpy.array(wg_trans2)\n",
    "\n",
    "show_grid(wg_shift[2,2,:,:], r\"\\tilde G^{shift}\",size=kernel_support, norm=.5)\n",
    "show_grid(wg_trans[2,2,:,:], r\"\\tilde G^{trans}\",size=kernel_support, norm=.5)\n",
    "show_grid(wg_trans2[2,2,:,:], r\"\\tilde G^{trans2}\",size=kernel_support, norm=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the complex conjugate,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = numpy.conj(wg_trans2)\n",
    "show_grid(wg[2,2], r\"$G^{shift\\ast}(u,v,w)\", size=kernel_support, norm=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our convolution kernel, we need to find out where we should grid our visibility data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fraccoord(N, p, Qpx):\n",
    "    \"\"\"Compute whole and fractional parts of coordinates, rounded to Qpx-th fraction of pixel size\n",
    "    :param N: Number of pixels in total \n",
    "    :param p: coordinates in range -1,1\n",
    "    :param Qpx: Fractional values to round to\n",
    "    \"\"\"\n",
    "    H=N/2\n",
    "    x=(1+p)*H\n",
    "    flx=numpy.floor(x + 0.5 /Qpx)\n",
    "    fracx=numpy.around(((x-flx)*Qpx))    \n",
    "    return (flx).astype(int), fracx.astype(int)\n",
    "\n",
    "uvw_sub = uvw_trans[ilow:ihigh,:]/L2 # extract subarray for w-slice\n",
    "(x, xf), (y, yf) = [fraccoord(grid_uv.shape[i], uvw_sub[:,i], over_sampling) for i in [0,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can convolve the data onto the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convgridone(a, pi, fi, gcf, v):\n",
    "    \"\"\"Convolve and grid one visibility sample\"\"\"\n",
    "    sy, sx= gcf[0][0].shape[0]/2, gcf[0][0].shape[1]/2\n",
    "    v *= numpy.exp(2j*numpy.pi*(pi[0]-N/2))\n",
    "    \n",
    "    # NB the order of fi below \n",
    "    a[ pi[1]-sy: pi[1]+sy+1, pi[0]-sx: pi[0]+sx+1 ] += gcf[fi[1],fi[0]]*v\n",
    "    return a\n",
    "\n",
    "def gridone(a,p,v):\n",
    "    \"\"\"grid one visibility without convolution\"\"\"\n",
    "    \n",
    "    a[p[1],p[0]] += v\n",
    "    \n",
    "    return a\n",
    "\n",
    "grid_uv=numpy.zeros([N, N], dtype=complex)\n",
    "grid_wt=numpy.zeros([N, N], dtype=complex)\n",
    "vis_sub = vis_trans[ilow:ihigh]\n",
    "for i in range(len(vis_sub)):\n",
    "#    gridone(grid_uv, (x[i],y[i]), vis_sub[i])\n",
    "    convgridone(grid_uv,(x[i], y[i]), (xf[i], yf[i]), wg, vis_sub[i])\n",
    "    convgridone(grid_wt,(x[i], y[i]), (xf[i], yf[i]), wg, 1.0+0j)\n",
    "\n",
    "show_grid(grid_uv, \"V\")\n",
    "show_grid(grid_wt, \"V^{psf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's FT this grid to check it gives a sensible map..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dty_image=numpy.fft.fftshift(numpy.fft.ifft2(numpy.fft.ifftshift(grid_uv)))\n",
    "psf_image=numpy.fft.fftshift(numpy.fft.ifft2(numpy.fft.ifftshift(grid_wt)))\n",
    "\n",
    "show_image(dty_image, name=\"I\")\n",
    "show_image(psf_image, name=\"I^{psf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dty_image_last = dty_image\n",
    "psf_image_last = psf_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signal = psf_image[(psf_image.shape[0]/2-20):(psf_image.shape[0]/2+20),\n",
    "                   (psf_image.shape[1]/2-20):(psf_image.shape[1]/2+20)]\n",
    "\n",
    "print numpy.sum(numpy.abs(signal)) / (numpy.sum(numpy.abs(psf_image)) - numpy.sum(numpy.abs(signal)))\n",
    "\n",
    "pl.subplot(121)\n",
    "pl.imshow(signal.real)\n",
    "pl.title(\"PSF Signal\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_uv_o=numpy.zeros([N, N], dtype=complex)\n",
    "vis_sub_o = vis[ilow:ihigh]\n",
    "for i in range(len(vis_sub)):\n",
    "    convgridone(grid_uv_o,(x[i], y[i]), (xf[i], yf[i]), wg, vis_sub[i])\n",
    "\n",
    "ff = (1/T2/4) * numpy.mgrid[-ff_size:ff_size-2./over_sampling:(ff_size*over_sampling*1j),\n",
    "                            -ff_size:ff_size-2./over_sampling:(ff_size*over_sampling*1j)]\n",
    "rot = numpy.exp(2j*numpy.pi*(ff[1] * delta_l + ff[0] * delta_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(0.000977731015697-0.000803955164319j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
