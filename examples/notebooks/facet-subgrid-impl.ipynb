{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facetted subgrids - Implementation\n",
    "\n",
    "This notebook is about implementation of the algorithm sketched out in [facet-subgrid.ipynb](facet-subgrid.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pylab\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.path as path\n",
    "\n",
    "from ipywidgets import interact\n",
    "import numpy\n",
    "import sys\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import scipy.special\n",
    "import math\n",
    "pylab.rcParams['figure.figsize'] = 16, 10\n",
    "pylab.rcParams['image.cmap'] = 'viridis'\n",
    "\n",
    "try:\n",
    "    sys.path.append('../..')\n",
    "    from crocodile.synthesis import *\n",
    "    from util.visualize import *\n",
    "    print(\"Crocodile mode\")\n",
    "except ImportError:\n",
    "    print(\"Stand-alone mode\")\n",
    "    # Convolution and FFT helpers\n",
    "    def conv(a, b): return ifft(fft(a) * fft(b))\n",
    "    def coordinates(N):\n",
    "        return numpy.fft.fftshift(numpy.fft.fftfreq(N))\n",
    "    def fft(a):\n",
    "        if len(a.shape) == 1: return numpy.fft.fftshift(numpy.fft.fft(numpy.fft.ifftshift(a)))\n",
    "        elif len(a.shape) == 2: return numpy.fft.fftshift(numpy.fft.fft2(numpy.fft.ifftshift(a)))\n",
    "    def ifft(a):\n",
    "        if len(a.shape) == 1: return numpy.fft.fftshift(numpy.fft.ifft(numpy.fft.ifftshift(a)))\n",
    "        elif len(a.shape) == 2: return numpy.fft.fftshift(numpy.fft.ifft2(numpy.fft.ifftshift(a)))\n",
    "    def pad_mid(a, N):\n",
    "        N0 = a.shape[0]\n",
    "        assert N >= N0\n",
    "        return numpy.pad(a, len(a.shape) * [(N//2-N0//2, (N+1)//2-(N0+1)//2)], mode='constant', constant_values=0.0)\n",
    "    def extract_mid(a, N):\n",
    "        assert N <= a.shape[0]\n",
    "        cx = a.shape[0] // 2\n",
    "        s = N // 2\n",
    "        if N % 2 == 0:\n",
    "            return a[len(a.shape) * [slice(cx - s, cx + s)]]\n",
    "        else:\n",
    "            return a[len(a.shape) * [slice(cx - s, cx + s + 1)]]\n",
    "    def anti_aliasing_function(shape, m, c):\n",
    "        if len(numpy.array(shape).shape) == 0:\n",
    "            mult = 2 - 1/shape/4\n",
    "            return scipy.special.pro_ang1(m, m, c, mult*coordinates(shape))[0]\n",
    "        return numpy.outer(anti_aliasing_function(shape[0], m, c),\n",
    "                           anti_aliasing_function(shape[1], m, c))\n",
    "    def coordinates2(N):\n",
    "        N2 = N // 2\n",
    "        if N % 2 == 0:\n",
    "            return numpy.mgrid[-N2:N2, -N2:N2][::-1] / N\n",
    "        else:\n",
    "            return numpy.mgrid[-N2:N2+1, -N2:N2+1][::-1] / N\n",
    "    def _show(a, name, scale, axes):\n",
    "        size = a.shape[0]\n",
    "        if size % 2 == 0:\n",
    "            low,high = -0.5, 0.5 * (size - 2) / size\n",
    "        else:\n",
    "            low,high = -0.5 * (size - 1) / size, 0.5 * (size - 1) / size\n",
    "        low = (low - 1/size/2) * scale\n",
    "        high = (high - 1/size/2) * scale\n",
    "        cax=axes.imshow(a, extent=(low,high,low,high)); axes.set_title(name);\n",
    "        axes.figure.colorbar(cax,shrink=.4,pad=0.025)\n",
    "    def show_grid(grid, name, theta, axes):\n",
    "        return _show(grid, name, theta, axes)\n",
    "    def show_image(img, name, theta, axes):\n",
    "        return _show(img, name, img.shape[0] / theta, axes)\n",
    "    def extract_oversampled(a, Qpx, N):\n",
    "        result = numpy.empty((Qpx, N), dtype=complex)\n",
    "        for xf in range(Qpx):\n",
    "            # Determine start offset.\n",
    "            mx = a.shape[0]//2 - Qpx*(N//2) + xf\n",
    "            # Extract every Qpx-th pixel\n",
    "            result[xf] = a[mx : mx+Qpx*N : Qpx]\n",
    "        return result\n",
    "    def kernel_oversample(ff, Qpx, s=None):\n",
    "        # Pad the far field to the required pixel size\n",
    "        N = ff.shape[0]\n",
    "        if s is None: s = N\n",
    "        padff = pad_mid(ff, N*Qpx)\n",
    "        # Obtain oversampled uv-grid\n",
    "        af = fft(padff)\n",
    "        # Extract kernels\n",
    "        return extract_oversampled(af, Qpx, s)\n",
    "\n",
    "# Helper for marking ranges in a graph\n",
    "def mark_range(lbl, x0, x1, y0=None, y1=None, ax=None):\n",
    "    if ax is None: ax = pylab.gca()\n",
    "    if y0 is None: y0 = ax.get_ylim()[1]\n",
    "    if y1 is None: y1 = ax.get_ylim()[0]\n",
    "    wdt = ax.get_xlim()[1] - ax.get_xlim()[0]\n",
    "    ax.add_patch(patches.PathPatch(patches.Path([(x0,y0), (x0,y1)]), linestyle=\"dashed\"))\n",
    "    ax.add_patch(patches.PathPatch(patches.Path([(x1,y0), (x1,y1)]), linestyle=\"dashed\"))\n",
    "    if pylab.gca().get_yscale() == 'linear':\n",
    "        lbl_y = (y0*7+y1) / 8\n",
    "    else: # Some type of log scale\n",
    "        lbl_y = (y0**7*y1)**(1/8)\n",
    "    ax.annotate(lbl, (x1+wdt/200, lbl_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_approx(yB, yN, xN, alpha=0, dim=1, hexagon=False):\n",
    "    # gridding error\n",
    "    assert yB < yN\n",
    "    pswf = anti_aliasing_function(int(yN)*2, alpha, 2*numpy.pi*yN*xN)\n",
    "    pswf /= numpy.prod(numpy.arange(2*alpha-1,0,-2, dtype=float)) # double factorial    \n",
    "    grid_error = numpy.abs(numpy.sum(pswf[::2] - pswf[1::2]))\n",
    "    # correction error\n",
    "    b_error = numpy.abs(pswf[int(yN) + int(yB)])\n",
    "    if dim >= 2 and hexagon:\n",
    "        b_error *= numpy.abs(pswf[int(yN) + int(yB/2)])**(dim-1)\n",
    "    else:\n",
    "        b_error **= dim\n",
    "    return numpy.abs(grid_error) / (2*xM) / b_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrisation\n",
    "\n",
    "Let us a have another look at the parameters that go into our algorithm. How general can we be, and how can we optimise values to give us more speed and flexibility?\n",
    "\n",
    "Firstly, note that we do not actually care too much about $x_A$ and $y_B$ here: They need to be bounds on $A_i$ and $B_j$ respectively, but they can always be higher. There is also no reason for all $A_i$ and $B_j$ to be the same pattern shifted in image/grid space: They can be entirely arbitrary.\n",
    "\n",
    "This means that given the sampling rate $N$, we can simply round up the sizes used to represent $A$ and $B$, as well as the number of facets/subgrids needed to cover the space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "N = 512\n",
    "yB = N / 8\n",
    "xA = 1 / 8\n",
    "xA_size = int(math.ceil(xA*2*N))\n",
    "yB_size = int(math.ceil(yB*2))\n",
    "print(\"image_size=%d, xA_size=%d, yB_size=%d\" % (N, xA_size, yB_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose \"gridding\" function extents\n",
    "\n",
    "On the other hand, $x_N$ and $x_M$ are a bit more critical. The accuracy of our approximation depends on:\n",
    "\n",
    "1. The $2\\pi x_Ny_N$ product, which becomes the prolate spheroidal wave function parameter. Too low, and we get a bad approximation, too large, and we hit numeric instabilities\n",
    "2. The $\\frac{x_N}{x_B}$ margin, which decides how much we allow $b$ to magnify up our error\n",
    "\n",
    "This is further complicated by the fact that $x_M \\ge x_A + 2x_N$ must:\n",
    "\n",
    "1. be as small as possible, as it directly scales the exchanged data size and multiple FFTs,\n",
    "2. satisfy $\\frac 1{2x_M} \\in \\mathbb N$ to allow us to down-sample cheaply, and\n",
    "3. also satisfy $2x_MN \\in \\mathbb N$, as otherwise the set of allowable subgrid offsets will shrink significantly (see below)\n",
    "\n",
    "The easiest way to explore the parameter space with this many restrictions is to settle on a given overhead ($x_My_N$ product) and enumerate the options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overhead = 2.2\n",
    "alpha = 0\n",
    "max_par = 100\n",
    "err_best = 10000\n",
    "xM_step_best = xM_best = xN_best = yN_best = None\n",
    "for xM_step in numpy.arange(int(numpy.ceil(1 / 2 / xA)), 1, -1):\n",
    "    if N % xM_step != 0:\n",
    "        continue\n",
    "    xM = 1 / 2 / xM_step\n",
    "    xN = (xM - xA) / 2\n",
    "    yN = numpy.floor(overhead * xA * yB / xM)\n",
    "    par = 2 * numpy.pi * xN * yN\n",
    "    if xN < 1 / N:\n",
    "        continue\n",
    "    print(\"xM = 1/%d, xN = %.4f, yN = %d, par = %.1f\" % (xM_step*2, xN, yN, par), flush=True, end=\"\")\n",
    "    if yN <= yB or par > max_par:\n",
    "        print(\", par too high\")\n",
    "        break\n",
    "    err = error_approx(yB, yN, xN, alpha=alpha)\n",
    "    print(\", err = %g\" % (err))\n",
    "    if err < err_best:\n",
    "        err_best = err; xM_step_best = xM_step; xM_best = xM; xN_best = xN; yN_best = yN\n",
    "xM_step = xM_step_best; xM = xM_best; xN = xN_best; yN = yN_best\n",
    "print(\"Chose xM=1/%d\" % (xM_step*2))\n",
    "\n",
    "xM_size = int(2*xM*N)\n",
    "xM_yN_size = int(numpy.ceil(xM*2*yN*2))\n",
    "yN_size = xM_yN_size * xM_step\n",
    "print(\"xM_size=%d, xM_yN_size=%d, yN_size=%d\" % (xM_size, xM_yN_size, yN_size))\n",
    "print(\"xM_step=%d\" % xM_step)\n",
    "\n",
    "print(yB, yN)\n",
    "print(\"(Parameters for Sze-Tan: x0=%f, R=%d)\" % (yB / yN / 2, int(numpy.floor(xN*2*yN))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placing facets and subgrids\n",
    "\n",
    "The next step is to decide where to place facets and subgrids. All facet/subgrid centre locations must align with the grids on both sides. This means that with facet/grid centres $x_{0,i}$ and $y_{0,j}$ we want:\n",
    "\n",
    "$$\\forall i,j: \\quad x_{0,i} y_{0,j} \\in \\mathbb Z$$\n",
    "\n",
    "What we need to do here is to separate the sampling rate $N$ into two factors $N_xN_y = N$ with $N_x,N_y \\in \\mathbb N$. This allows us to define a \"grid\" of safe facet and subgrid centres:\n",
    "\n",
    "$$\\frac{Nx_{0,i}}{N_x} = N_yx_{0,i} \\in \\mathbb Z, \\quad \\frac{y_{0,i}}{N_y} \\in \\mathbb Z$$\n",
    "\n",
    "as clearly the product of those two terms is in $\\mathbb Z$ and equal to $x_{0,i}y_{0,i}$. An additional side condition here is that we want\n",
    "$$N_yx_M \\in \\mathbb N $$\n",
    "This is saying that we only permit facet offset steps $N_y$ that lie on the coarser $x_M$ grid. What this does is selecting for parameters where the grid size reduction (same as convolution with comb function) becomes a simple selection operator in image space. This will permit an optimisation later.\n",
    "\n",
    "What we therefore have to do is find subgrid/facet locations satisfying these conditions by rounding them to the next permissable centre for a number of $N_x$ and $N_y$ options. We have to keep in mind that for the purpose of this exercise we still want all facets and subgrids to cover the entire image / grid collectively. This might even require us to increase the number of facets/subgrids past the mathematically minimum number, introducing further \"rounding\" overhead for unfriendly configurations. Note that for real applications we might actually have a lot more wiggle room here, as we could skip known-zero parts of the image/grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsubgrid = int(math.ceil(N / xA_size))\n",
    "nfacet = int(math.ceil(N / yB_size))\n",
    "\n",
    "best_maxdxdy = N; best_subgrid_off = None; best_facet_off = None; best_ny = N\n",
    "while best_subgrid_off is None:\n",
    "\n",
    "    print(\"Trying %d sub-grids, %d facets (%.1f%% overhead):\" \n",
    "         % (nsubgrid, nfacet, 100 * (1 / (N / nsubgrid / xA_size * N / nfacet / yB_size) - 1)))\n",
    "    facet_y0s = numpy.arange(nfacet) * N / nfacet\n",
    "    subgrid_x0s = numpy.arange(nsubgrid) / nsubgrid\n",
    "\n",
    "    warnx_count = 0; warny_count = 0\n",
    "    for Ny in xM_step * numpy.arange(1, N // xM_step):\n",
    "        if N % Ny != 0:\n",
    "            continue\n",
    "        Nx = N // Ny\n",
    "        subgrid_off = Nx * numpy.round(N * subgrid_x0s / Nx)\n",
    "        facet_off = Ny * numpy.round(facet_y0s / Ny)\n",
    "        maxdx = numpy.max(numpy.abs(subgrid_off - N * subgrid_x0s))\n",
    "        maxdy = numpy.max(numpy.abs(facet_off - facet_y0s))\n",
    "        warnx = warny = \"\"\n",
    "        if maxdx > (xA_size - N / nsubgrid) / 2:\n",
    "            warnx = \" (> %.1f!)\" % ((xA_size - N / nsubgrid) / 2)\n",
    "            warnx_count+=1\n",
    "        if maxdy > (yB_size - N / nfacet) / 2:\n",
    "            warny = \" (> %.1f!)\" % ((yB_size - N / nfacet) / 2)\n",
    "            warny_count+=1\n",
    "        print(\"Nx=%d, Ny=%d, maxdx=%.1f%s, maxdy=%.1f%s\" % (Nx, Ny, maxdx, warnx, maxdy, warny))\n",
    "        # Select \n",
    "        if warnx == \"\" and warny == \"\" and best_ny > Ny:\n",
    "            # best_maxdxdy > max(maxdx, maxdy):\n",
    "            best_maxdxdy = max(maxdx, maxdy)\n",
    "            best_subgrid_off = subgrid_off.astype(int)\n",
    "            best_facet_off = facet_off.astype(int)\n",
    "            best_ny = Ny\n",
    "    # No solution found? Crudely use number of warnings as indicator what we need more of\n",
    "    if best_subgrid_off is None:\n",
    "        if warnx_count >= warny_count:\n",
    "            nsubgrid += 1\n",
    "        else:\n",
    "            nfacet += 1\n",
    "assert best_maxdxdy != N\n",
    "subgrid_off = best_subgrid_off\n",
    "facet_off = best_facet_off\n",
    "Nx = N // best_ny; Ny = best_ny;\n",
    "print (\"Chose Nx=%d, Ny=%d, N*x0s=%s, y0s=%s\" % (N // Ny, Ny, subgrid_off, facet_off))\n",
    "def whole(xs): return numpy.all(numpy.abs(xs - numpy.around(xs)) < 1e-13)\n",
    "assert whole(numpy.outer(subgrid_off, facet_off) / N)\n",
    "assert whole(facet_off*xM_size/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(figsize=(16, 1)); pylab.title(\"Subgrid Centre Offsets\")\n",
    "pylab.plot(((subgrid_off+N//2)%N-N//2)/N,numpy.zeros_like(subgrid_off), \"b|\", markersize=30);\n",
    "pylab.plot(coordinates(N//Nx), numpy.zeros(N//Nx), \"g|\")\n",
    "pylab.xlim(-.5,.5); pylab.yticks([])\n",
    "for i, x in enumerate(subgrid_x0s):\n",
    "    mark_range(\"$x_{0,%d}$\"%i, 0, (x + .5) % 1 - .5)\n",
    "pylab.figure(figsize=(16, 1)); pylab.title(\"Facet Centre Offsets\")\n",
    "pylab.plot((facet_off+N//2)%N-N//2,numpy.zeros_like(facet_off), \"b|\", markersize=30);\n",
    "pylab.plot(coordinates(N//Ny)*N, numpy.zeros(N//Ny), \"g|\")\n",
    "pylab.xlim(-N/2,N/2); pylab.yticks([])\n",
    "for i, y in enumerate(facet_y0s):\n",
    "    mark_range(\"$y_{0,%d}$\"%i, 0, (y + N//2) % N - N//2)\n",
    "pylab.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizing the intermediate grid\n",
    "\n",
    "Next, we need to choose $y_P$. We are relatively free in doing so, we just need to make sure that\n",
    "\n",
    "1. we satisfy $y_P \\ge y_B + \\frac 12 y_B$ and\n",
    "2. $2x_My_P \\in \\mathbb N$ so we can down-sample easily.\n",
    "\n",
    "However note that down the road, solving FFTs of size $y_PN$ and $x_My_P$ is going to represent most of our computation. Therefore we want to make sure that we do not choose a size here that is either much larger than we need - or gets factored into large prime factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greatest_prime_factor(x):\n",
    "    i = 2\n",
    "    while i * i <= x:\n",
    "        while i < x and x % i == 0:\n",
    "            x //= i\n",
    "        i += 1\n",
    "    return x\n",
    "\n",
    "yP_size_options = (int(numpy.ceil( int(yB+yN*2) / Ny )) + numpy.arange(0,12)) * Ny \n",
    "yP_size_primes = numpy.vectorize(greatest_prime_factor)(yP_size_options)\n",
    "print(\", \".join([\"%d: %d\" % yp for yp in zip(yP_size_options, yP_size_primes)]))\n",
    "yP_size = yP_size_options[numpy.argmin(yP_size_primes)]\n",
    "print(\"Chose yP_size = %d (%.1f %% overhead)\" % (yP_size, 100 * yP_size / (yB_size/2+yN_size) - 100))\n",
    "\n",
    "assert whole(subgrid_off*yP_size/N)\n",
    "\n",
    "xM_yP_size = int(xM*2*yP_size)\n",
    "xMxN_yP_size = xM_yP_size + 2*int(numpy.ceil(xN*yP_size)) # same margin both sides\n",
    "print(\"yP_size=%d, xM_yP_size=%d, xMxN_yP_size=%d\" % (yP_size, xM_yP_size, xMxN_yP_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = numpy.random.rand(N)-0.5\n",
    "FG = fft(G)\n",
    "\n",
    "subgrid = numpy.empty((nsubgrid, xA_size), dtype=complex)\n",
    "subgrid_A = numpy.zeros_like(subgrid, dtype=int)\n",
    "subgrid_border = (subgrid_off + numpy.hstack([subgrid_off[1:],[N]])) // 2\n",
    "print(subgrid_border)\n",
    "for i in range(nsubgrid):\n",
    "    left = (subgrid_border[i-1] - subgrid_off[i] + xA_size//2) % N\n",
    "    right = subgrid_border[i] - subgrid_off[i] + xA_size//2\n",
    "    assert left >= 0 and right <= xA_size, \"xA not large enough to cover subgrids!\"\n",
    "    subgrid_A[i,left:right] = 1\n",
    "    subgrid[i] = subgrid_A[i] * extract_mid(numpy.roll(G, -subgrid_off[i]), xA_size)\n",
    "\n",
    "facet = numpy.empty((nfacet, yB_size), dtype=complex)\n",
    "facet_B = numpy.zeros_like(facet, dtype=bool)\n",
    "facet_split = numpy.array_split(range(N), nfacet)\n",
    "facet_border = (facet_off + numpy.hstack([facet_off[1:],[N]])) // 2\n",
    "print(facet_border)\n",
    "for j in range(nfacet):\n",
    "    left = (facet_border[j-1] - facet_off[j] + yB_size//2) % N\n",
    "    right = facet_border[j] - facet_off[j] + yB_size//2\n",
    "    assert left >= 0 and right <= yB_size, \"yB not large enough to cover facets!\"\n",
    "    facet_B[j,left:right] = 1\n",
    "    facet[j] = facet_B[j] * extract_mid(numpy.roll(FG, -facet_off[j]), yB_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a bunch of array constants derived from the gridding function:\n",
    " * $\\mathcal Fb$ ($y_B$ size)\n",
    " * $\\mathcal Fn$ ($y_N$ size, sampled at $x_M$ rate), as well as \n",
    " * $\\mathcal Fm' = \\mathcal Fn\\mathcal Fm$ term ($y_P$ size, sampled at $x_M+x_N$).\n",
    " \n",
    "For the convolution with $b$, $n$, and cheap multiplication with $m$ at $y_P$ image size respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pswf = anti_aliasing_function(yN_size, alpha, 2*numpy.pi*yN*xN).real\n",
    "pylab.semilogy(extract_mid(numpy.abs(fft(pswf)), int(numpy.floor(xN*2*yN*2))), \"s\")\n",
    "Fb = 1/extract_mid(pswf, yB_size)\n",
    "Fn = pswf[(yN_size//2)%int(1/2/xM)::int(1/2/xM)]\n",
    "facet_m0_trunc = pswf * numpy.sinc(coordinates(yN_size)*xM_size/N*yN_size)\n",
    "facet_m0_trunc = xM_size*yP_size/N * extract_mid(ifft(pad_mid(facet_m0_trunc, yP_size)), xMxN_yP_size).real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facet $\\rightarrow$ Subgrid\n",
    "\n",
    "With a few more slight optimisations we arrive at a compact representation for our algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N / 5, yP_size / 5, yN_size/ 5)\n",
    "xN_yP_size = xMxN_yP_size - xM_yP_size\n",
    "RNjMiBjFj = numpy.empty((nsubgrid, nfacet, xM_yN_size), dtype=complex)\n",
    "for j in range(nfacet):\n",
    "    BjFj = ifft(pad_mid(facet[j] * Fb, yP_size))\n",
    "    for i in range(nsubgrid):\n",
    "        MiBjFj = facet_m0_trunc * extract_mid(numpy.roll(BjFj, -subgrid_off[i]*yP_size//N), xMxN_yP_size)\n",
    "        MiBjFj_sum = numpy.array(extract_mid(MiBjFj, xM_yP_size))\n",
    "        MiBjFj_sum[:xN_yP_size//2] += MiBjFj[-xN_yP_size//2:]\n",
    "        MiBjFj_sum[-xN_yP_size//2:] += MiBjFj[:xN_yP_size//2:]\n",
    "        RNjMiBjFj[i,j] = Fn * extract_mid(fft(MiBjFj_sum), xM_yN_size)\n",
    "\n",
    "# - redistribution of RNjMiBjFj here -\n",
    "\n",
    "fig = pylab.figure(figsize=(16, 8))\n",
    "ax1, ax2 = fig.add_subplot(211), fig.add_subplot(212)\n",
    "err_sum = err_sum_img = 0\n",
    "for i in range(nsubgrid):\n",
    "    approx = numpy.zeros(xM_size, dtype=complex)\n",
    "    for j in range(nfacet):\n",
    "        approx += numpy.roll(pad_mid(RNjMiBjFj[i,j], xM_size), facet_off[j]*xM_size//N)\n",
    "    approx = subgrid_A[i] * extract_mid(ifft(approx), xA_size)\n",
    "    \n",
    "    ax1.semilogy(xA*2*coordinates(xA_size), numpy.abs( approx - subgrid[i] ))\n",
    "    ax2.semilogy(N*coordinates(xA_size), numpy.abs( fft(approx - subgrid[i]) ))    \n",
    "    err_sum += numpy.abs(approx - subgrid[i])**2\n",
    "    err_sum_img += numpy.abs(fft(approx - subgrid[i]))**2\n",
    "mark_range(\"$x_A$\", -xA, xA, ax=ax1); mark_range(\"$N/2$\", -N/2, N/2, ax=ax2)\n",
    "print(\"RMSE:\", numpy.sqrt(numpy.mean(err_sum)), \"(image:\", numpy.sqrt(numpy.mean(err_sum_img)), \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgrid $\\rightarrow$ facet\n",
    "\n",
    "The other direction works similarly, now we want:\n",
    "$$F_j \\approx b_j \\ast \\sum_i m_i (n_j \\ast S_i)$$\n",
    "\n",
    "We run into a very similar problem with $m$ as when reconstructing subgrids, except this time it happens because we want to construct:\n",
    "$$ b_j \\left( m_i (n_j \\ast S_i)\\right)\n",
    "  = b_j \\left( \\mathcal F^{-1}\\left[\\Pi_{2y_P} \\mathcal F m_i\\right] (n_j \\ast S_i)\\right)$$\n",
    "\n",
    "As usual, this is entirely dual: In the previous case we had a signal limited by $y_B$ and needed the result of the convolution up to $y_N$, whereas now we have a signal bounded by $y_N$, but need the convolution result up to $y_B$. This cancels out - therefore we are okay with the same choice of $y_P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNjSi = numpy.empty((nsubgrid, nfacet, xM_yN_size), dtype=complex)\n",
    "for i in range(nsubgrid):\n",
    "    FSi = fft(pad_mid(subgrid[i], xM_size))\n",
    "    for j in range(nfacet):\n",
    "        FNjSi[i,j] = extract_mid(numpy.roll(FSi, -facet_off[j]*xM_size//N), xM_yN_size)\n",
    "\n",
    "# - redistribution of FNjSi here -\n",
    "\n",
    "fig = pylab.figure(figsize=(16, 8))\n",
    "ax1, ax2 = fig.add_subplot(211), fig.add_subplot(212)\n",
    "err_sum = err_sum_img = 0\n",
    "for j in range(nfacet):\n",
    "    approx = numpy.zeros(yB_size, dtype=complex)\n",
    "    for i in range(nsubgrid):\n",
    "        NjSi = numpy.zeros(xMxN_yP_size, dtype=complex)\n",
    "        NjSi_mid = extract_mid(NjSi, xM_yP_size)\n",
    "        NjSi_mid[:] = ifft(pad_mid(Fn * FNjSi[i,j], xM_yP_size)) # updates NjSi_tile via reference!\n",
    "        NjSi[-xN_yP_size//2:] = NjSi_mid[:xN_yP_size//2]\n",
    "        NjSi[:xN_yP_size//2:] = NjSi_mid[-xN_yP_size//2:]\n",
    "        FMiNjSi = fft(numpy.roll(pad_mid(facet_m0_trunc * NjSi, yP_size), subgrid_off[i]*yP_size//N))\n",
    "        approx += extract_mid(FMiNjSi, yB_size)\n",
    "    approx *= Fb * facet_B[j]\n",
    "\n",
    "    err_sum += numpy.abs(ifft(approx - facet[j]))**2\n",
    "    err_sum_img += numpy.abs(approx - facet[j])**2\n",
    "    ax1.semilogy(coordinates(yB_size), numpy.abs(ifft(facet[j] - approx)))\n",
    "    ax2.semilogy(yB_size*coordinates(yB_size), numpy.abs(facet[j] - approx))\n",
    "print(\"RMSE:\", numpy.sqrt(numpy.mean(err_sum)), \"(image:\", numpy.sqrt(numpy.mean(err_sum_img)), \")\")\n",
    "mark_range(\"$x_A$\", -xA, xA, ax=ax1)\n",
    "mark_range(\"$x_M$\", -xM, xM, ax=ax1)\n",
    "mark_range(\"$y_B$\", -yB, yB, ax=ax2)\n",
    "mark_range(\"$0.5$\", -.5, .5, ax=ax1)\n",
    "pylab.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D case\n",
    "\n",
    "All of this generalises to two dimensions in the way you would expect. Let us set up test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nsubgrid,\"x\",nsubgrid,\"subgrids,\",nfacet,\"x\", nfacet,\"facets\")\n",
    "subgrid_2 = numpy.empty((nsubgrid, nsubgrid, xA_size, xA_size), dtype=complex)\n",
    "facet_2 = numpy.empty((nfacet, nfacet, yB_size, yB_size), dtype=complex)\n",
    "\n",
    "G_2 = numpy.exp(2j*numpy.pi*numpy.random.rand(N,N))*numpy.random.rand(N,N)/2\n",
    "for i0,i1 in itertools.product(range(nsubgrid), range(nsubgrid)):\n",
    "    subgrid_2[i0,i1] = extract_mid(numpy.roll(G_2, (-subgrid_off[i0], -subgrid_off[i1]), (0,1)), xA_size)\n",
    "    subgrid_2[i0,i1] *= numpy.outer(subgrid_A[i0], subgrid_A[i1])\n",
    "FG_2 = fft(G_2)\n",
    "for j0,j1 in itertools.product(range(nfacet), range(nfacet)):\n",
    "    facet_2[j0,j1] = extract_mid(numpy.roll(FG_2, (-facet_off[j0], -facet_off[j1]), (0,1)), yB_size)\n",
    "    facet_2[j0,j1] *= numpy.outer(facet_B[j0], facet_B[j1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the amount of data has been squared, performance is a bit more of a concern now. Fortunately, the entire procedure is completely separable, so let us first re-define the operations to work on one array axis exclusively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slice_a(fill_val, axis_val, dims, axis):\n",
    "    return [ axis_val if i == axis else fill_val for i in range(dims) ]\n",
    "def pad_mid_a(a, N, axis):\n",
    "    N0 = a.shape[axis]\n",
    "    if N == N0: return a\n",
    "    pad = slice_a((0,0), (N//2-N0//2, (N+1)//2-(N0+1)//2), \n",
    "                  len(a.shape), axis)    \n",
    "    return numpy.pad(a, pad, mode='constant', constant_values=0.0)\n",
    "def extract_mid_a(a, N, axis):\n",
    "    assert N <= a.shape[axis]\n",
    "    cx = a.shape[axis] // 2\n",
    "    if N % 2 != 0:\n",
    "        slc = slice(cx - N // 2, cx + N // 2 + 1)\n",
    "    else:\n",
    "        slc = slice(cx - N // 2, cx + N // 2)\n",
    "    return a[slice_a(slice(None), slc, len(a.shape), axis)]\n",
    "def fft_a(a, axis):\n",
    "    return numpy.fft.fftshift(numpy.fft.fft(numpy.fft.ifftshift(a, axis),axis=axis),axis)\n",
    "def ifft_a(a, axis):\n",
    "    return numpy.fft.fftshift(numpy.fft.ifft(numpy.fft.ifftshift(a, axis),axis=axis),axis)\n",
    "def broadcast_a(a, dims, axis):\n",
    "    slc = [numpy.newaxis] * dims\n",
    "    slc[axis] = slice(None)\n",
    "    return a[slc]\n",
    "def broadcast_a(a, dims, axis):\n",
    "    return a[slice_a(numpy.newaxis, slice(None), dims, axis)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to define the two fundamental operations - going from $F$ to $b\\ast F$ and from $b\\ast F$ to $n\\ast m(b\\ast F)$ separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_facet(facet, axis):\n",
    "    BF = pad_mid_a(facet * broadcast_a(Fb, len(facet.shape), axis), yP_size, axis)\n",
    "    return ifft_a(BF, axis)\n",
    "def extract_subgrid(BF, i, axis):\n",
    "    dims = len(BF.shape)\n",
    "    BF_mid = extract_mid_a(numpy.roll(BF, -subgrid_off[i]*yP_size//N, axis), xMxN_yP_size, axis)\n",
    "    MBF = broadcast_a(facet_m0_trunc,dims,axis) * BF_mid\n",
    "    MBF_sum = numpy.array(extract_mid_a(MBF, xM_yP_size, axis))\n",
    "    xN_yP_size = xMxN_yP_size - xM_yP_size\n",
    "    # [:xN_yP_size//2] / [-xN_yP_size//2:] for axis, [:] otherwise\n",
    "    slc1 = slice_a(slice(None), slice(xN_yP_size//2), dims, axis)\n",
    "    slc2 = slice_a(slice(None), slice(-xN_yP_size//2,None), dims, axis)\n",
    "    MBF_sum[slc1] += MBF[slc2]\n",
    "    MBF_sum[slc2] += MBF[slc1]\n",
    "    return broadcast_a(Fn,len(BF.shape),axis) * \\\n",
    "           extract_mid_a(fft_a(MBF_sum, axis), xM_yN_size, axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having those operations separately means that we can shuffle things around quite a bit without affecting the result. The obvious first choice might be to do all facet-preparation up-front, as this allows us to share the computation across all subgrids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "NMBF_NMBF = numpy.empty((nsubgrid, nsubgrid, nfacet, nfacet, xM_yN_size, xM_yN_size), dtype=complex)\n",
    "for j0,j1 in itertools.product(range(nfacet), range(nfacet)):\n",
    "    BF_F = prepare_facet(facet_2[j0,j1], 0)\n",
    "    BF_BF = prepare_facet(BF_F, 1)\n",
    "    for i0 in range(nsubgrid):\n",
    "        NMBF_BF = extract_subgrid(BF_BF, i0, 0)\n",
    "        for i1 in range(nsubgrid):\n",
    "            NMBF_NMBF[i0,i1,j0,j1] = extract_subgrid(NMBF_BF, i1, 1)\n",
    "print(time.time() - t, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, remember that `prepare_facet` increases the amount of data involved, which in turn means that we need to shuffle more data through subsequent computations.\n",
    "\n",
    "Therefore it is actually more efficient to first do the subgrid-specific reduction, and *then* continue with the (constant) facet preparation along the other axis. We can tackle both axes in whatever order we like, it doesn't make a difference for the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "for j0,j1 in itertools.product(range(nfacet), range(nfacet)):\n",
    "    BF_F = prepare_facet(facet_2[j0,j1], 0)\n",
    "    for i0 in range(nsubgrid):\n",
    "        NMBF_F = extract_subgrid(BF_F, i0, 0)\n",
    "        NMBF_BF = prepare_facet(NMBF_F, 1)\n",
    "        for i1 in range(nsubgrid):\n",
    "            NMBF_NMBF[i0,i1,j0,j1] = extract_subgrid(NMBF_BF, i1, 1)\n",
    "print(time.time() - t, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "for j0,j1 in itertools.product(range(nfacet), range(nfacet)):\n",
    "    F_BF = prepare_facet(facet_2[j0,j1], 1)\n",
    "    for i1 in range(nsubgrid):\n",
    "        F_NMBF = extract_subgrid(F_BF, i1, 1)\n",
    "        BF_NMBF = prepare_facet(F_NMBF, 0)\n",
    "        for i0 in range(nsubgrid):\n",
    "            NMBF_NMBF[i0,i1,j0,j1] = extract_subgrid(BF_NMBF, i0, 0)\n",
    "print(time.time() - t, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = 16, 8\n",
    "err_sum = err_sum_img = 0\n",
    "for i0,i1 in itertools.product(range(nsubgrid), range(nsubgrid)):\n",
    "    approx = numpy.zeros((xM_size, xM_size), dtype=complex)\n",
    "    for j0,j1 in itertools.product(range(nfacet), range(nfacet)):\n",
    "        approx += numpy.roll(pad_mid(NMBF_NMBF[i0,i1,j0,j1], xM_size),\n",
    "                             (facet_off[j0]*xM_size//N, facet_off[j1]*xM_size//N), (0,1))\n",
    "    approx = extract_mid(ifft(approx), xA_size)\n",
    "    approx *= numpy.outer(subgrid_A[i0], subgrid_A[i1])\n",
    "    err_sum += numpy.abs(approx - subgrid_2[i0,i1])**2 / nsubgrid**2\n",
    "    err_sum_img += numpy.abs(fft(approx - subgrid_2[i0,i1]))**2 / nsubgrid**2\n",
    "pylab.imshow(numpy.log(numpy.sqrt(err_sum)) / numpy.log(10)); pylab.colorbar(); pylab.show()\n",
    "pylab.imshow(numpy.log(numpy.sqrt(err_sum_img)) / numpy.log(10)); pylab.colorbar(); pylab.show()\n",
    "print(\"RMSE:\", numpy.sqrt(numpy.mean(err_sum)), \"(image:\", numpy.sqrt(numpy.mean(err_sum_img)), \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degridding\n",
    "\n",
    "To use this for radio astronomy, our goal in this context is to (de)grid visibilities from subgrids. This uses very similar machinery - in fact, what we described so far can simply be re-expressed as gridding or degridding all points of a sub-grid using facets. Difference being that our method is a lot faster and requires less data movement.\n",
    "\n",
    "However, this does similarity does not actually buy us much: While for the recombination we consider the fields of view of facets, for gridding visibilities we are interested in the \"global\" field of view. Therefore we need a different grid correction and gridder that gets applied before and after we have done the combination, respectively.\n",
    "\n",
    "The full size of the considered image is fixed to $N$, therefore our effective image size is $2x_0N$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = 16, 4\n",
    "\n",
    "gc_alpha = 0; xGp = 5/N; gc_x0 = 0.35\n",
    "gc_support = int(2*xGp*N)\n",
    "print(\"parameter:\", numpy.pi*gc_support/2, \"x0:\", gc_x0)\n",
    "x0_size = int(N*gc_x0*2)\n",
    "gc_pswf = anti_aliasing_function(N, gc_alpha, numpy.pi*gc_support/2)\n",
    "gc = pad_mid(extract_mid(1 / gc_pswf, x0_size), N)\n",
    "pylab.semilogy(x0_size*coordinates(x0_size), numpy.abs(extract_mid(gc, x0_size))); pylab.legend([\"F[n]\"]);\n",
    "pylab.xlim((-N/1.8, N/1.8))\n",
    "mark_range(\"$x_0N$\", -gc_x0*N,gc_x0*N);\n",
    "mark_range(\"$N/2$\", -N/2,N/2); pylab.title(\"Grid correction\"); pylab.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we derive the new $\\mathcal F G$ that we are going to feed to the recombination algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FG_2_gc = FG_2 * numpy.outer(gc, gc)\n",
    "show_image(numpy.log(numpy.maximum(1e-15, numpy.abs(FG_2_gc))) / numpy.log(10), \"FG_2_cropped\", N)\n",
    "G_2_gc = ifft(FG_2_gc)\n",
    "crop = pad_mid(numpy.ones(x0_size), N)\n",
    "G_2_cropped = ifft(FG_2 * numpy.outer(crop,crop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which in turn leads to new facets. Note how the grid correction pattern is clearly larger than any individual facet.\n",
    "\n",
    "The other thing to notice here is that due to the grid correction margin a significant portion of the image is now zero, which translates to entire facets being zero. Due to the linearity of the method this means we could simply skip those. For the purpose of this notebook we do not use this, but it is a good optimisation to keep in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgrid_2 = numpy.empty((nsubgrid, nsubgrid, xA_size, xA_size), dtype=complex)\n",
    "facet_2 = numpy.empty((nfacet, nfacet, yB_size, yB_size), dtype=complex)\n",
    "for i0,i1 in itertools.product(range(nsubgrid), range(nsubgrid)):\n",
    "    subgrid_2[i0,i1] = extract_mid(numpy.roll(G_2_gc, (-subgrid_off[i0], -subgrid_off[i1]), (0,1)), xA_size)\n",
    "    subgrid_2[i0,i1] *= numpy.outer(subgrid_A[i0], subgrid_A[i1])\n",
    "fig = pylab.figure(figsize=(32,32))\n",
    "for j0,j1 in itertools.product(range(nfacet), range(nfacet)):\n",
    "    facet_2[j0,j1] = extract_mid(numpy.roll(FG_2_gc, (-facet_off[j0], -facet_off[j1]), (0,1)), yB_size)\n",
    "    facet_2[j0,j1] *= numpy.outer(facet_B[j0], facet_B[j1])\n",
    "    show_image(numpy.log(numpy.maximum(1e-15, numpy.abs(facet_2[j0,j1]))) / numpy.log(10),\n",
    "               \"facet_%d%d\" % (j0,j1), N, axes=fig.add_subplot(nfacet,nfacet,j1+(nfacet-j0-1)*nfacet+1),\n",
    "              norm=(-15,8))\n",
    "pylab.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recombination algorithm again, using the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMBF_NMBF = numpy.empty((nsubgrid, nsubgrid, nfacet, nfacet, xM_yN_size, xM_yN_size), dtype=complex)\n",
    "for j0,j1 in itertools.product(range(nfacet), range(nfacet)):\n",
    "    F_BF = prepare_facet(facet_2[j0,j1], 1)\n",
    "    for i1 in range(nsubgrid):\n",
    "        F_NMBF = extract_subgrid(F_BF, i1, 1)\n",
    "        BF_NMBF = prepare_facet(F_NMBF, 0)\n",
    "        for i0 in range(nsubgrid):\n",
    "            NMBF_NMBF[i0,i1,j0,j1] = extract_subgrid(BF_NMBF, i0, 0)\n",
    "\n",
    "from pylru import lrudecorator\n",
    "@lrudecorator(100)\n",
    "def make_approx_subgrid(i0,i1):\n",
    "    approx = numpy.zeros((xM_size, xM_size), dtype=complex)\n",
    "    for j0,j1 in itertools.product(range(nfacet), range(nfacet)):\n",
    "        approx += numpy.roll(pad_mid(NMBF_NMBF[i0,i1,j0,j1], xM_size),\n",
    "                             (facet_off[j0]*xM_size//N, facet_off[j1]*xM_size//N), (0,1))\n",
    "    # Extract region that is set in subgrid for comparison\n",
    "    approx_compare = extract_mid(ifft(approx), xA_size)\n",
    "    approx_compare *= numpy.outer(subgrid_A[i0], subgrid_A[i1])\n",
    "    rmse = numpy.sqrt(numpy.mean(numpy.abs(approx_compare - subgrid_2[i0,i1])**2 / nsubgrid**2))\n",
    "    # Return full approximation. We degrid from it, so bounds don't matter\n",
    "    return ifft(approx), rmse / numpy.mean(numpy.abs(approx_compare))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain visibilities at non-integer positions we need an oversampled gridding function, as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = 2**14\n",
    "print(\"grid support:\", gc_support)\n",
    "print(\"oversampling:\", oversample)\n",
    "kernel = kernel_oversample(gc_pswf, oversample, gc_support).real\n",
    "kernel /= numpy.sum(kernel[0])\n",
    "r = numpy.arange(-oversample*(gc_support//2), oversample*((gc_support+1)//2)) / oversample\n",
    "pylab.semilogy(r, numpy.transpose(kernel).flatten().real); mark_range(\"$Nx_G$\", -N*xGp,N*xGp);\n",
    "pylab.title(\"Gridding kernel (oversampled x%d)\" % oversample); pylab.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(iu=(0, N, 0.01),iv=(0, N, 0.01))\n",
    "def test_degrid_accuracy(iu,iv, show_subgrid=False):\n",
    "    u = (iu - N//2) / N; v = (iv - N//2) / N\n",
    "    su = numpy.sum((iu+N//2)%N >= subgrid_border) % nsubgrid\n",
    "    sv = numpy.sum((iv+N//2)%N >= subgrid_border) % nsubgrid\n",
    "    siu = iu + xA_size//2-(subgrid_off[su] + N//2) % N\n",
    "    siv = iv + xA_size//2-(subgrid_off[sv] + N//2) % N\n",
    "    \n",
    "    dAM = (xM_size - xA_size) // 2\n",
    "    deg = conv_predict(N, 1, numpy.array([(u,v,0)]), None, G_2_gc, kernel)[0]\n",
    "    if whole(iu) and whole(iv):\n",
    "        actual = G_2_cropped[int(iv),int(iu)]\n",
    "        print(\"actual:       \", actual)\n",
    "        print(\"degridded:    \", deg)\n",
    "        print(\"degrid error: \", numpy.abs(deg-actual))\n",
    "    else:\n",
    "        print(\"degridded:    \", deg)\n",
    "    \n",
    "    approx_subgrid, rmse = make_approx_subgrid(sv, su)\n",
    "    print(\"subgrid:       (%d/%d), rmse: %g\" % (su, sv, rmse))\n",
    "    \n",
    "    sou = (((subgrid_off[su] + N//2) % N) - N//2) / N\n",
    "    sov = (((subgrid_off[sv] + N//2) % N) - N//2) / N\n",
    "    deg_ap = conv_predict(N, 2*xM, numpy.array([(u-sou,v-sov,0)]), None, approx_subgrid, kernel)[0]\n",
    "    print(\"recomb+degrid:\", deg_ap);\n",
    "    print(\"recomb error: \", numpy.abs(deg_ap-deg))\n",
    "    if whole(iu) and whole(iv):\n",
    "        print(\"total error:  \", numpy.abs(deg_ap-actual))\n",
    "        \n",
    "    if show_subgrid:\n",
    "        fig = pylab.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        show_grid(numpy.abs(numpy.log(approx_subgrid) / numpy.log(10)), \"subgrid_%d%d\" % (su,sv), N, axes=ax)\n",
    "        ax.add_patch(patches.Rectangle((u-sou-gc_support//2/N, v-sov-gc_support//2/N),\n",
    "                                       gc_support/N, gc_support/N, fill=False))\n",
    "        pylab.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import h5py\n",
    "\n",
    "out_prefix = \"../../data/grid/T05_\"\n",
    "\n",
    "with open(out_prefix + \"pswf.in\", \"w\") as f:\n",
    "    numpy.fft.ifftshift(pswf).tofile(f)\n",
    "\n",
    "for j0,j1 in itertools.product(range(nfacet), range(nfacet)):\n",
    "    \n",
    "    with open(out_prefix + \"facet%d%d.in\" % (j0,j1), \"w\") as f:\n",
    "        numpy.fft.ifftshift(facet_2[j0,j1]).tofile(f)\n",
    "    for i0,i1 in itertools.product(range(nsubgrid), range(nsubgrid)):\n",
    "        with open(out_prefix + \"nmbf%d%d%d%d.in\" % (i0,i1,j0,j1), \"w\") as f:\n",
    "            numpy.fft.ifftshift(NMBF_NMBF[i0,i1,j0,j1]).tofile(f)\n",
    "\n",
    "for i0,i1 in itertools.product(range(nsubgrid), range(nsubgrid)):\n",
    "    with open(out_prefix + \"approx%d%d.in\" % (i0,i1), \"w\") as f:\n",
    "        numpy.fft.ifftshift(make_approx_subgrid(i0, i1)[0]).tofile(f)\n",
    "        \n",
    "with h5py.File(out_prefix + \"kernel.h5\",'w') as f:\n",
    "    f['sepkern/kern'] = kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
