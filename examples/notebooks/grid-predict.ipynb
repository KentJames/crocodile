{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "import itertools\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.special\n",
    "import time\n",
    "import random\n",
    "\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "from crocodile.synthesis import *\n",
    "from crocodile.simulate import *\n",
    "from crocodile.antialias import *\n",
    "from util.visualize import *\n",
    "from arl.test_support import create_named_configuration, export_visibility_to_hdf5\n",
    "from arl.data_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some grid characteristics. Only theta is actually important here, the rest is just decides the range of the example $u/v$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = 0.1\n",
    "lam = 18000\n",
    "grid_size = int(theta * lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine $u/v$ gridding function to use. Three choices here - trivial, Sze-Tan's version and PSWF. `x0` decides how much of the image coordinate space we can actually use without errors rising.\n",
    "\n",
    "We use that to calculate the appropriate grid step length `du` for good accuracy in our target field of view `theta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa_over = 4096\n",
    "aa_support = 6\n",
    "aa_x0 = 0.25\n",
    "aa_mode = 0\n",
    "aa_szetan = True\n",
    "if aa_support == 1:\n",
    "    print(\"Using trivial gridder\")\n",
    "    aa_gcf = numpy.ones((aa_over, aa_support))\n",
    "    def aa(x): return 1\n",
    "elif aa_szetan:\n",
    "    print(\"Using Sze-Tan's gridder with R=%d, x_0=%g\" % (aa_support//2, aa_x0))\n",
    "    aa_gcf = sze_tan_gridder(aa_support//2, aa_x0, aa_over)\n",
    "    def aa(x):\n",
    "        return sze_tan_grid_correction_gen(aa_support//2, aa_x0, x)\n",
    "    print(\"Mean error:\", sze_tan_mean_error(aa_support//2, aa_x0))\n",
    "else:\n",
    "    aa_parameter = aa_support\n",
    "    print(\"Using PSWF with mode %d and parameter %g\" % (aa_mode, aa_parameter))\n",
    "    aa_gcf = kernel_oversample(anti_aliasing_function(grid_size, aa_mode, aa_parameter), aa_over, aa_support)\n",
    "    aa_gcf /= numpy.sum(aa_gcf[0])\n",
    "    def aa(x):\n",
    "        return scipy.special.pro_ang1(aa_mode, aa_mode, aa_parameter, 2*x)[0]\n",
    "    \n",
    "# Calculate appropriate step length to give us full accuracy for a field of view of size theta\n",
    "du = du_opt = aa_x0/(theta/2)\n",
    "print(\"Optimal du =\", du)\n",
    "\n",
    "# Plot gridding function\n",
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "r = numpy.arange(-aa_over*(aa_support//2), aa_over*((aa_support+1)//2)) / aa_over\n",
    "plt.plot(du_opt*r, numpy.transpose(aa_gcf).flatten().real);\n",
    "plt.xticks(du_opt*numpy.arange(-(aa_support//2), ((aa_support+1)//2)+1))\n",
    "plt.grid(True);plt.xlabel('u/v [$\\lambda$]');plt.title('$u/v$ Gridder');plt.show()\n",
    "\n",
    "# Plot grid correction function\n",
    "theta_x0 = theta/aa_x0/2\n",
    "x = coordinates(101)\n",
    "plt.plot(theta*x/aa_x0/2, aa(x));\n",
    "plt.title('$u/v$ Grid correction');plt.grid(True);plt.xlabel('l [1]')\n",
    "plt.axvspan(theta/2, theta_x0/2, color='lightgray', hatch='x', alpha=0.5)\n",
    "plt.axvspan(-theta/2, -theta_x0/2, color='lightgray', hatch='x', alpha=0.5)\n",
    "plt.annotate('(unused)', xy=((theta+theta_x0)/4,0.9), ha='center', color='gray')\n",
    "plt.annotate('(unused)', xy=(-(theta+theta_x0)/4,0.9), ha='center', color='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa_support_w = 4\n",
    "aa_x0_w = 0.125\n",
    "aa_parameter_w = aa_support_w\n",
    "aa_szetan_w = True\n",
    "if aa_support_w == 1:\n",
    "    print(\"Using trivial gridder\")\n",
    "    aa_gcf_w = numpy.ones((aa_over, aa_support_w))\n",
    "    def aa_w(x): return 1\n",
    "elif aa_szetan_w:\n",
    "    print(\"Using Sze-Tan's gridder with R=%d, x_0=%g\" % (aa_support_w//2, aa_x0_w))\n",
    "    aa_gcf_w = sze_tan_gridder(aa_support_w//2, aa_x0_w, aa_over)\n",
    "    def aa_w(x):\n",
    "        return sze_tan_grid_correction_gen(aa_support_w//2, aa_x0_w, x)\n",
    "    print(\"Mean error:\", sze_tan_mean_error(aa_support_w//2, aa_x0_w))\n",
    "else:\n",
    "    aa_gcf_w = kernel_oversample(anti_aliasing_function(grid_size, 0, aa_parameter_w), aa_over, aa_support_w)\n",
    "    aa_gcf_w /= numpy.sum(aa_gcf_w[0])\n",
    "    def aa_w(x):\n",
    "        return scipy.special.pro_ang1(aa_mode, aa_mode, aa_parameter_w, 2*x)[0]\n",
    "\n",
    "# Calculate appropriate step length to give us full accuracy for a field of view of size theta\n",
    "max_n = 1.0 - numpy.sqrt(1.0 - 2*(theta/2)**2)\n",
    "print(\"max_n =\", max_n)\n",
    "dw = dw_opt = aa_x0_w / max_n\n",
    "print(\"Optimal dw =\", dw)\n",
    "\n",
    "# Plot gridding function\n",
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "r = numpy.arange(-aa_over*(aa_support_w//2), aa_over*((aa_support_w+1)//2)) / aa_over\n",
    "plt.plot(dw_opt*r, numpy.transpose(aa_gcf_w).flatten().real);\n",
    "plt.xticks(dw_opt*numpy.arange(-(aa_support_w//2), ((aa_support_w+1)//2)+1))\n",
    "plt.grid(True); plt.xlabel('w [$\\lambda$]'); plt.title('$w$ Gridder'); plt.show()\n",
    "\n",
    "x = coordinates(101)\n",
    "plt.plot(max_n*x/aa_x0_w, aa_w(x));\n",
    "plt.title('$w$ Grid correction'); plt.grid(True); plt.xlabel('$n$ [1]');\n",
    "max_n_x0 = max_n/aa_x0_w/2\n",
    "plt.axvspan(max_n, max_n_x0, color='lightgray', hatch='x', alpha=0.5)\n",
    "plt.axvspan(-max_n, -max_n_x0, color='lightgray', hatch='x', alpha=0.5)\n",
    "plt.annotate('(unused)', xy=((max_n+max_n_x0)/2,0.9), ha='center', color='gray')\n",
    "plt.annotate('(unused)', xy=(-(max_n+max_n_x0)/2,0.9), ha='center', color='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate some sources on the sky. We use a random pattern to make reasonably sure that we are not hand-picking a good sky pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Npt = 500\n",
    "points = theta * (numpy.random.rand(Npt,2)-0.5)\n",
    "\n",
    "#points = list(theta/10 * numpy.array(list(itertools.product(range(-5, 6), range(-5, 6)))))\n",
    "#points.append((theta/3,0))\n",
    "#points = numpy.array(points)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 8, 8\n",
    "plt.scatter(points[:,0], points[:,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up code to predict visibilities - either directly or by visibilities weighted by the grid correction and offset in a grid-like fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(dist_uvw, du=du_opt, dw=dw_opt, apply_aa = False, apply_aa_w = False):\n",
    "    # Get image coordinates\n",
    "    ls, ms = numpy.transpose(points)\n",
    "    ns = numpy.sqrt(1.0 - ls**2 - ms**2) - 1\n",
    "    # Evaluate grid correction functions in uv & w\n",
    "    aas = numpy.ones(len(ls))\n",
    "    if apply_aa:\n",
    "        aas *= aa(du*ls) * aa(du*ms)\n",
    "    if apply_aa_w:\n",
    "        aas *= aa_w(dw*ns)\n",
    "    # Now simulate points, dividing out grid correction\n",
    "    vis = 0\n",
    "    for l,m, a in zip(ls, ms, aas):\n",
    "        vis += simulate_point(dist_uvw, l, m) / a\n",
    "    return vis\n",
    "\n",
    "def predict_grid(u,v,w,ov_u,ov_v,ov_w,du=du_opt, dw=dw_opt, visualise=False):\n",
    "    \n",
    "    # Generate offsets that we are going to sample at\n",
    "    ius, ivs, iws = numpy.meshgrid(numpy.arange(aa_support), numpy.arange(aa_support), numpy.arange(aa_support_w))\n",
    "    dus = du*(ius.flatten()-(aa_support//2)+ov_u/aa_over)\n",
    "    dvs = du*(ivs.flatten()-(aa_support//2)+ov_v/aa_over)\n",
    "    dws = dw*(iws.flatten()-(aa_support_w//2)+ov_w/aa_over)\n",
    "    \n",
    "    # Get grid convolution function for offsets\n",
    "    aas = aa_gcf[ov_u,ius.flatten()] * aa_gcf[ov_v,ivs.flatten()] * aa_gcf_w[ov_w,iws.flatten()]\n",
    "\n",
    "    # Add offsets to all uvw coordinates\n",
    "    us = numpy.array(u)[:,numpy.newaxis] + dus[numpy.newaxis,:]\n",
    "    vs = numpy.array(v)[:,numpy.newaxis] + dvs[numpy.newaxis,:]\n",
    "    ws = numpy.array(w)[:,numpy.newaxis] + dws[numpy.newaxis,:]\n",
    "    \n",
    "    # Visualise sampling pattern?\n",
    "    if visualise:\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        ax.scatter(us,vs,ws, color='red');\n",
    "        ax.set_xlabel('u'); ax.set_ylabel('v'); ax.set_zlabel('w')\n",
    "\n",
    "    # Predict visibilities\n",
    "    vis = predict(numpy.transpose([us.flatten(),vs.flatten(),ws.flatten()]),\n",
    "                  du=du, dw=dw, apply_aa=True, apply_aa_w=True).reshape(us.shape)\n",
    "    \n",
    "    # Convolve with gridder, sum up\n",
    "    return numpy.sum(vis * aas[numpy.newaxis,:], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the performance of the sampling over a wide variety of parameters. Note that `u`,`v` and `w` do not actually matter too much, but we get into trouble quickly by increasing `du` or `dw` -- that is when we start using our gridder for inaccurate image coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@interact(u=(-lam/2,lam/2,0.1),v=(-lam/2,lam/2,0.1),w=(-lam/2,lam/2,0.1),\n",
    "          ov_u=(0,aa_over-1), ov_v=(0,aa_over-1), ov_w=(0,aa_over-1),\n",
    "          du=(du_opt/10,du_opt*2,du_opt/10), dw=(dw_opt/10,dw_opt*2,dw_opt/10))\n",
    "def test(u=0,v=0,w=0, ov_u=0,ov_v=0,ov_w=0, du=du_opt, dw=dw_opt):\n",
    "    vis = predict(numpy.transpose([[u],[v],[w]]))\n",
    "    print(\"Direct: \", vis[0])\n",
    "    vis_sum = predict_grid([u],[v],[w],ov_u,ov_v,ov_w,du,dw)\n",
    "    print(\"Grid:   \", vis_sum[0])\n",
    "    print(\"Error:  \", numpy.abs(vis[0]-vis_sum[0]) / numpy.sqrt(Npt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a quick statistic by feeding in a good couple of points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 500\n",
    "us = lam * (numpy.random.rand(N)-0.5)\n",
    "vs = lam * (numpy.random.rand(N)-0.5)\n",
    "ws = lam * (numpy.random.rand(N)-0.5)\n",
    "ov_u = random.randint(0, aa_over-1)\n",
    "ov_v = random.randint(0, aa_over-1)\n",
    "ov_w = random.randint(0, aa_over-1)\n",
    "vis = predict(numpy.transpose([us,vs,ws]))\n",
    "grid_vis = predict_grid(us,vs,ws,ov_u,ov_v,ov_w)\n",
    "diff = numpy.abs(vis-grid_vis)\n",
    "mean_err = numpy.sqrt(numpy.mean(diff**2)) / numpy.mean(numpy.abs(vis))\n",
    "print(\"Mean error:\", mean_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for small supports in $w$ the error actually depends quite a bit on the oversampling value in $w$, with the worst case happening for even pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if aa_support_w < 4:\n",
    "    ov_ws = numpy.arange(0, aa_over, aa_over//16)\n",
    "    errs = []\n",
    "    for ov_w in ov_ws:\n",
    "        grid_vis = predict_grid(us,vs,ws,ov_u,ov_v,ov_w)\n",
    "        diff = numpy.abs(vis-grid_vis)\n",
    "        errs.append(numpy.sqrt(numpy.mean(diff**2)) / numpy.mean(numpy.abs(vis)))\n",
    "    plt.yscale('log'); plt.xlabel('w mod %f' % dw_opt); plt.ylabel('error')\n",
    "    plt.plot(ov_ws/aa_over*dw_opt, errs);\n",
    "else:\n",
    "    print(\"Nothing to see here...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duws = numpy.meshgrid(\n",
    "    du_opt * numpy.arange(0.25, 2, 0.25),\n",
    "    dw_opt * numpy.arange(0.25, 2, 0.25))\n",
    "mean_errs = []\n",
    "for du_, dw_ in zip(duws[0].flatten(), duws[1].flatten()):\n",
    "    grid_vis = predict_grid(us,vs,ws,ov_u,ov_v,ov_w, du_,dw_)\n",
    "    mean_errs.append(numpy.sqrt(numpy.mean(numpy.abs(vis-grid_vis)**2)) / numpy.mean(numpy.abs(vis)))\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_wireframe(duws[0]/du_opt, duws[1]/dw_opt,\n",
    "                  numpy.log(numpy.array(mean_errs)).reshape(duws[0].shape) / numpy.log(10))\n",
    "ax.set_xlabel('du'); ax.set_ylabel('dw'); ax.set_zlabel('log10 error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_cache = { tuple(k): sze_tan_mean_error(KERNEL_CACHE[k]['R'], KERNEL_CACHE[k]['x0']) for k in KERNEL_CACHE.keys() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_n = 1.0 - numpy.sqrt(1.0 - 2*(theta/2)**2)\n",
    "def get_cost(N, x0u, Ru, x0w, Rw, inc, margin=8*15, rho=1, verbose=False):\n",
    "    max_u = N / theta\n",
    "    max_w = inc * max_u\n",
    "    dw = x0w / max_n\n",
    "    wplanes = numpy.ceil(max_w / dw) + (Rw*2 - 1)\n",
    "    if verbose:\n",
    "        print(max_u, \" max_u\")\n",
    "        print(max_w, \" max_w\")\n",
    "        print(max_n, \" max_n\")\n",
    "        print(wplanes, \"w-planes\")\n",
    "    \n",
    "    # Cost for gridding rho * NxN visibilities (real-valued kernel)\n",
    "    #   4 (2 Ru)^2 (2 Rw) rho N^2\n",
    "    Nvis = rho * (N-margin)**2\n",
    "    cost_grid = 4 * 8 * Ru**2 * Rw * Nvis\n",
    "    if verbose:\n",
    "        print(4 * 8 * Ru**2 * Rw, \"flop per vis\")\n",
    "    \n",
    "    # Cost for NxN FFT, assuming x_0 useable image space:\n",
    "    #   5 (N/x_0)^2 log_2 (N/x_0)\n",
    "    cost_fft = 10 * (N / x0u)**2 * numpy.log(N / x0u) / numpy.log(2)\n",
    "    if verbose:\n",
    "        print(\"%dx%d FFT\" % (N / x0u, N / x0u))\n",
    "        print(cost_fft, \"flops per FFT\")\n",
    "    return (cost_grid + wplanes * cost_fft) / Nvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@interact(N=(256, 4096, 128), x0u=(0.01, 0.5, 0.01), x0w=(0.01, 0.5, 0.01), \n",
    "          Ru=(1,5), Rw=(1,5), inc=(0,1,0.05), margin=(15,10*15))\n",
    "def test_cost(N=512, x0u=aa_x0, Ru=aa_support//2, x0w=aa_x0_w, Rw=aa_support_w//2,\n",
    "              margin=8*15, inc=0.2, rho=100):\n",
    "    print(\"Cost/vis:\", get_cost(N, x0u, Ru, x0w, Rw, inc, margin, rho, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_cost(N, max_prec, rho, inc=0.2):\n",
    "    best = None\n",
    "    best_cost = 1e15\n",
    "    for uk in KERNEL_CACHE.keys():\n",
    "        if cost_cache[uk] > max_prec: continue\n",
    "        for wk in KERNEL_CACHE.keys():\n",
    "            if cost_cache[wk] > max_prec: continue\n",
    "            x0u = KERNEL_CACHE[uk]['x0']\n",
    "            x0w = KERNEL_CACHE[wk]['x0']\n",
    "            Ru = KERNEL_CACHE[uk]['R']\n",
    "            Rw = KERNEL_CACHE[wk]['R']\n",
    "            cost = get_cost(N, x0u, Ru, x0w, Rw, inc, rho=rho)\n",
    "            if cost < best_cost:\n",
    "                best_cost = cost\n",
    "                best = (uk, wk)\n",
    "    return (best_cost,\n",
    "            KERNEL_CACHE[best[0]]['R'], KERNEL_CACHE[best[0]]['x0'],\n",
    "            KERNEL_CACHE[best[1]]['R'], KERNEL_CACHE[best[1]]['x0'])\n",
    "\n",
    "#print(\"Best cost: \", best_cost)\n",
    "#print(\"Best kernels: \", best)\n",
    "#get_cost_cache(best[0], best[1], verbose=True)\n",
    "\n",
    "@interact(N=(128, 2048, 128), max_prec_exp=(-10, -3, 0.5), rho=(0.01,1000), inc=(0,1,0.05))\n",
    "def test_find_best_cost(N=512, max_prec_exp=-5, rho=50, inc=0.1):\n",
    "    best_cost, best_Ru, best_x0u, best_Rw, best_x0w = \\\n",
    "        find_best_cost(N, numpy.exp(max_prec_exp * numpy.log(10)), rho, inc)\n",
    "    print(\"Best cost:  %d flop/vis\" % best_cost)\n",
    "    print(\"u/v Kernel: R=%d, x0=%g\" % (best_Ru, best_x0u))\n",
    "    print(\"w Kernel:   R=%d, x0=%g\" % (best_Rw, best_x0w))\n",
    "    get_cost(N, best_x0u, best_Ru, best_x0w, best_Rw, inc, rho=rho, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_precs, rhos = numpy.meshgrid(\n",
    "    numpy.exp(numpy.arange(-8, -1, 0.25) * numpy.log(10)),\n",
    "    2**numpy.arange(3, 10)\n",
    ")\n",
    "best_costs, best_Rus, best_x0us, best_Rws, best_x0ws = \\\n",
    "  numpy.vectorize(find_best_cost)(512, max_precs, rhos)\n",
    "for data, lbl in [(best_costs, \"Cost\"), (best_x0us, \"x0u\"), (best_Rus, \"Ru\"), \n",
    "                                        (best_x0ws, \"x0w\"), (best_Rws, \"Rw\")]:\n",
    "    plt.xscale('log'); plt.xlabel('Error'); plt.ylabel(lbl); plt.title(\"Optimal %s for error\" % lbl)\n",
    "    for i in range(rhos.shape[0]):\n",
    "        plt.plot(max_precs[i], data[i], label=\"rho=%d\" % rhos[i,0])\n",
    "    plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ns, rhos = numpy.meshgrid(\n",
    "    numpy.arange(2**8, 2**11, 2**7),\n",
    "    2**numpy.arange(4, 10)\n",
    ")\n",
    "best_costs, best_Rus, best_x0us, best_Rws, best_x0ws = \\\n",
    "  numpy.vectorize(find_best_cost)(Ns, 1e-5, rhos)\n",
    "for data, lbl in [(best_costs, \"Cost\"), (Ns/best_x0us, \"Neff\")]:\n",
    "    plt.xlabel('N'); plt.ylabel(lbl);\n",
    "    for i in range(Ns.shape[0]):\n",
    "        plt.plot(Ns[i], data[i], label=\"rho=%d\" % rhos[i,0])\n",
    "    plt.legend(); plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(24*24*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
