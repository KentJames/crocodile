{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Illustration of predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from matplotlib import pylab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 12, 10\n",
    "\n",
    "import functools\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.special\n",
    "\n",
    "from crocodile.clean import *\n",
    "from crocodile.synthesis import *\n",
    "from crocodile.simulate import *\n",
    "from util.visualize import *\n",
    "from arl.test_support import create_named_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate baseline coordinates for an observation with a hypothetical north-pole VLA over 6 hours, with a visibility recorded every 10 minutes. The phase center is fixed in the zenith. This results in constant $w$-values of basically zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlas = create_named_configuration('VLAA_north')\n",
    "ha_range = numpy.arange(numpy.radians(0),\n",
    "                        numpy.radians(90),\n",
    "                        numpy.radians(90 / 36))\n",
    "dec = numpy.radians(90)\n",
    "vobs = xyz_to_baselines(vlas.data['xyz'], ha_range, dec)\n",
    "\n",
    "# Wavelength: 5 metres \n",
    "wvl=5\n",
    "uvw = vobs / wvl\n",
    "\n",
    "ax = plt.figure().add_subplot(111, projection='3d')\n",
    "ax.scatter(uvw[:,0], uvw[:,1] , uvw[:,2])\n",
    "max_uvw = numpy.amax(uvw)\n",
    "ax.set_xlabel('U [$\\lambda$]'); ax.set_xlim((-max_uvw, max_uvw))\n",
    "ax.set_ylabel('V [$\\lambda$]'); ax.set_ylim((-max_uvw, max_uvw))\n",
    "ax.set_zlabel('W [$\\lambda$]'); ax.set_zlim((-max_uvw, max_uvw))\n",
    "ax.view_init(20, 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make an image with a grid of sources to generate visibilities from. For reference we also use a direct Fourier Transform to generate visibilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "theta = 2*0.01\n",
    "lam = 18000\n",
    "grid_size = int(theta * lam)\n",
    "image = numpy.zeros((grid_size, grid_size))\n",
    "\n",
    "vis = numpy.zeros(len(uvw), dtype=complex)\n",
    "for l,m in theta/10 * numpy.array(list(itertools.product(range(-3, 4), range(-3, 4)))):\n",
    "    vis += 1.0*simulate_point(uvw, l, m)\n",
    "    image[grid_size//2 + int(m*lam),\n",
    "          grid_size//2 + int(l*lam)] += 1.0\n",
    "show_image(image, \"image\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can attempt to generate visibilities from the image. The quality of this depends quite a bit on the quality of the used anti-aliasing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vis_simple = do_predict(theta, lam, uvw, None, image, simple_predict)\n",
    "print(\"Simple: \", numpy.sum(numpy.abs(vis_simple - vis)**2) / numpy.sum(numpy.abs(vis)**2))\n",
    "\n",
    "oversample = 1024\n",
    "\n",
    "supports = numpy.arange(2,14)\n",
    "mrange = numpy.arange(0.9, 2.0, 0.1)\n",
    "conv_errs = []\n",
    "for support in supports:\n",
    "    condition = support\n",
    "    aaf = anti_aliasing_function(grid_size, 0, support)\n",
    "    kv1 = kernel_oversample(aaf, oversample, support)\n",
    "    kv1 /= numpy.sum(kv1[0])\n",
    "    vis_conv = do_predict(theta, lam, uvw, None, image/numpy.outer(aaf,aaf), conv_predict, kv=kv1)\n",
    "    conv_errs.append(numpy.sum(numpy.abs(vis_conv - vis)**2))\n",
    "    print(\"Convolution %dx%d: \" % (support, support),\n",
    "          numpy.sum(numpy.abs(vis_conv - vis)**2) / numpy.sum(numpy.abs(vis)**2),\n",
    "          \" (mean off-centre\", numpy.abs(1-numpy.mean(vis_conv / vis)),\")\")\n",
    "\n",
    "# Show how error changes with support\n",
    "plt.semilogy(supports, conv_errs / numpy.sum(numpy.abs(vis)**2))\n",
    "plt.xlabel(\"Support, PSWF c\"); plt.ylabel(\"Error\"); plt.show()\n",
    "\n",
    "# Show error distribution\n",
    "plt.scatter(uvw[:,0], uvw[:,1], c=numpy.abs(vis_conv - vis))\n",
    "plt.scatter(-uvw[:,0], -uvw[:,1], c=numpy.abs(vis_conv - vis));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {
    "0813694c90594e5abd8289e866eb8202": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "a37fc7a335bd48708b8cdf1053a542cf": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
